@article{FriedmanArxiv,
	title = {Contrast Trees and Distribution Boosting},
	author = {Jerome Friedman},
	journal = {arXiv preprint  arXiv:1912.03785v1},
	url = {https://arxiv.org/abs/1912.03785},
	year = {2019}
}

@article {FriedmanPNAS,
	author = {Friedman, Jerome H.},
	title = {Contrast trees and distribution boosting},
	elocation-id = {201921562},
	year = {2020},
	doi = {10.1073/pnas.1921562117},
	publisher = {National Academy of Sciences},
	abstract = {Often machine learning methods are applied and results reported in cases where there is little to no information concerning accuracy of the output. Simply because a computer program returns a result does not ensure its validity. If decisions are to be made based on such results it is important to have some notion of their veracity. Contrast trees represent an approach for assessing the accuracy of many types of machine-learning estimates that are not amenable to standard validation methods. In situations where inaccuracies are detected boosted contrast trees can often improve performance. A special case, distribution boosting, provides an assumption-free method for estimating the full probability distribution of an outcome variable given any set of joint input predictor variable values.A method for decision tree induction is presented. Given a set of predictor variables x=(x1,x2,...,xp) and two outcome variables y and z associated with each x, the goal is to identify those values of x for which the respective distributions of y | x and z | x, or selected properties of those distributions such as means or quantiles, are most different. Contrast trees provide a lack-of-fit measure for statistical models of such statistics, or for the complete conditional distribution py(y | x), as a function of x. They are easily interpreted and can be used as diagnostic tools to reveal and then understand the inaccuracies of models produced by any learning method. A corresponding contrast-boosting strategy is described for remedying any uncovered errors, thereby producing potentially more accurate predictions. This leads to a distribution-boosting strategy for directly estimating the full conditional distribution of y at each x under no assumptions concerning its shape, form, or parametric representation.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/early/2020/08/14/1921562117},
	eprint = {https://www.pnas.org/content/early/2020/08/14/1921562117.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}
